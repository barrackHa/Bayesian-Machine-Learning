#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
BML EX0
\end_layout

\begin_layout Author
Barak Haim
\end_layout

\begin_layout Section
Linear Algebra
\end_layout

\begin_layout Subsection
Q form derivation 
\end_layout

\begin_layout Paragraph
Denote 
\begin_inset Formula $g_{1}(x)=x-\mu$
\end_inset

, 
\begin_inset Formula $g_{2}(x)=Rx$
\end_inset

 , 
\begin_inset Formula $g_{3}(x)=x$
\end_inset

 and 
\begin_inset Formula $g_{4}(x)=g_{3}(x)^{T}g_{2}(x)$
\end_inset

.
 So 
\begin_inset Formula $f_{1}(x)=g_{4}(g_{1}(x))=g_{3}^{T}(g_{1}(x))g_{2}(g_{1}(x))$
\end_inset

.
 By the chain role: 
\begin_inset Formula 
\[
\frac{\partial f_{1}}{\partial x}(x)=\frac{\partial(g_{4}\circ g_{1})}{\partial x}(x)=\frac{\partial g_{1}(x)}{\partial x}\frac{\partial g_{4}(g_{1}(x))}{\partial g_{1}(x)}=\bigstar
\]

\end_inset

Now - 
\begin_inset Formula $\frac{\partial g_{1}(x)}{\partial x}=\frac{\partial x}{\partial x}-\frac{\partial\mu}{\partial x}=1-0=1$
\end_inset

 and we get 
\begin_inset Formula $\bigstar=1\cdot\frac{\partial g_{4}(g_{1}(x))}{\partial g_{1}(x)}=\frac{\partial g_{4}(y)}{\partial y}$
\end_inset

 for 
\begin_inset Formula $y=g_{1}(x)$
\end_inset

.
 By the product role we get: 
\begin_inset Formula 
\[
\frac{\partial g_{4}(y)}{\partial y}=\frac{\partial(g_{3}^{T}\cdot g_{2})(y)}{\partial y}=\frac{\partial g_{3}(y)}{\partial y}^{T}g_{2}(y)+g_{3}(y)^{T}\frac{\partial g_{2}(y)}{\partial y}
\]

\end_inset

separately we have - 
\begin_inset Formula $\frac{\partial g_{3}(y)}{\partial y}=\frac{\partial y}{\partial y}=1$
\end_inset

 (same as 
\begin_inset Formula $g_{1}$
\end_inset

 only without the constant) and we're left with - 
\begin_inset Formula $\frac{\partial g_{2}(y)}{\partial y}$
\end_inset

.
 Since 
\begin_inset Formula $Ry=\left[\begin{array}{c}
\vdots\\
R_{i}^{T}y\\
\vdots
\end{array}\right]$
\end_inset

 where 
\begin_inset Formula $R_{i}^{T}$
\end_inset

 is the i'th row vector of R (in the recitation - eq 3.3 they're marked as
 
\begin_inset Formula $a_{i}'s$
\end_inset

).
 For each 
\begin_inset Formula $1\le i\le n$
\end_inset

 we get 
\begin_inset Formula $R_{i}^{T}y=\stackrel[j=1]{n}{\sum}R_{ij}y_{j}$
\end_inset

.
 The partial derivitve for 
\begin_inset Formula $1\le k\le n$
\end_inset

 is:
\begin_inset Formula 
\[
\frac{\partial}{\partial y_{k}}\stackrel[j=1]{n}{\sum}R_{ij}y_{j}=R_{ik}
\]

\end_inset

So long story short 
\begin_inset Formula $\frac{\partial g_{2}(y)}{\partial y}=R$
\end_inset

.
 All Togther now:
\begin_inset Formula 
\begin{align*}
 & \frac{\partial g_{3}(y)}{\partial y}^{T}g_{2}(y)+g_{3}(y)^{T}\frac{\partial g_{2}(y)}{\partial y}\\
= & 1Ry+(y^{T}R)\\
\underset{\varhexstar}{=} & Ry+(y^{T}R)^{T}=y^{T}(R^{T}+R)=(R+R^{T})y
\end{align*}

\end_inset

And 
\begin_inset Formula $\varhexstar$
\end_inset

 is just simbulic so we make sure we add to collumn vectors.
 Remeber 
\begin_inset Formula $y=x-\mu$
\end_inset

 and we get:
\begin_inset Formula 
\[
\frac{\partial f_{1}}{\partial x}(x)=(R+R^{T})(x-\mu)
\]

\end_inset


\end_layout

\begin_layout Paragraph
Now, assume 
\begin_inset Formula $R=R^{T}$
\end_inset

 (i.e.
 R is symmetric), we get 
\begin_inset Formula $R+R^{T}=2R$
\end_inset

 and so:
\begin_inset Formula 
\[
\frac{\partial f_{1}}{\partial x}(x)=2R(x-\mu)
\]

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset Formula $f_{2}(\theta)=\stackrel[i=1]{n}{\sum}(h_{i}^{T}\theta-y_{i})^{2}\overset{?}{=}\left\Vert H\theta-y\right\Vert ^{2}$
\end_inset


\end_layout

\begin_layout Paragraph
Denot 
\begin_inset Formula 
\[
H=\left[\begin{array}{ccc}
 & \vdots\\{}
[- & h_{i}^{T} & -]\\
 & \vdots
\end{array}\right]
\]

\end_inset

so - 
\begin_inset Formula $[H\theta]_{i}=h_{i}^{T}\theta$
\end_inset

 and 
\begin_inset Formula $h_{i}^{T}\theta-y_{i}=[H\theta]_{i}-y_{i}=[H\theta-y]_{i}$
\end_inset

 (
\begin_inset Formula $\bigstar$
\end_inset

).
 Now, by defintion:
\begin_inset Formula 
\[
\left\Vert H\theta-y\right\Vert ^{2}=(H\theta-y)^{T}(H\theta-y)=\sum(H\theta-y)_{i}\cdot(H\theta-y)=\sum(H\theta-y)_{i}^{2}
\]

\end_inset

Togther with 
\begin_inset Formula $\bigstar$
\end_inset

 we get 
\begin_inset Formula $\stackrel[i=1]{n}{\sum}(h_{i}^{T}\theta-y_{i})^{2}=\left\Vert H\theta-y\right\Vert ^{2}$
\end_inset


\end_layout

\begin_layout Subsection
\begin_inset Formula $f_{3}(\theta,\lambda)=-c\log\frac{1}{\lambda}-\frac{1}{2}\lambda\stackrel[i=1]{n}{\sum}(h_{i}^{T}\theta-y_{i})^{2}$
\end_inset


\end_layout

\begin_layout Paragraph
Denote 
\begin_inset Formula $g_{1}(\theta,\lambda)=\log\frac{1}{\lambda}=-\log\lambda$
\end_inset

 and 
\begin_inset Formula $g_{2}(\theta,\lambda)=\frac{\lambda}{2}\stackrel[i=1]{n}{\sum}(h_{i}^{T}\theta-y_{i})^{2}$
\end_inset

.
 We get that 
\begin_inset Formula $\frac{\partial g_{1}}{\partial\theta}(\theta,\lambda)=0$
\end_inset

 and 
\begin_inset Formula $\frac{\partial g_{1}}{\partial\lambda}(\theta,\lambda)=-\frac{1}{\lambda}$
\end_inset

.
 Futhermore - 
\begin_inset Formula $\frac{\partial g_{2}}{\partial\lambda}(\theta,\lambda)=\frac{1}{2}\stackrel[i=1]{n}{\sum}(h_{i}^{T}\theta-y_{i})^{2}$
\end_inset

.
 Last but not least, note 
\begin_inset Formula $\frac{\partial g_{2}}{\partial\theta}(\theta,\lambda)=\frac{\lambda}{2}\frac{\partial f_{2}}{\partial\theta}(\theta)$
\end_inset

.
 We saw in the recitation that 
\begin_inset Formula $\frac{\partial}{\partial y}g(y)=\frac{\partial}{\partial y}\left\Vert y\right\Vert ^{2}=2y$
\end_inset

.
 for 
\begin_inset Formula $f(x)=Hx-y$
\end_inset

 it holds that 
\begin_inset Formula $f_{2}(x)=g(f(x))$
\end_inset

.
 By the chain role - 
\begin_inset Formula $\frac{\partial f_{2}}{\partial x}(x)=\frac{\partial f}{\partial x}(x)\frac{\partial g}{\partial f(x)}(f(x))$
\end_inset

.
\begin_inset Formula 
\[
\frac{\partial(Hx-y)_{j}}{\partial x_{i}}=\frac{\partial(\sum_{k}H_{jk}x_{k}-y_{j})}{\partial x_{i}}=\frac{\partial(\sum_{k}H_{jk}x_{k})}{\partial x_{i}}-\frac{\partial y_{j}}{\partial x_{i}}=H_{ji}
\]

\end_inset

Hence - 
\begin_inset Formula $\frac{\partial f}{\partial x}(x)=\frac{\partial(Hx-y)}{\partial x}=H^{T}$
\end_inset

 and thus - 
\begin_inset Formula $\frac{\partial f_{2}}{\partial x}(x)=2H^{T}(Hx-y)$
\end_inset

.
 
\end_layout

\begin_layout Standard
To some it all up: 
\begin_inset Formula $f_{3}(\theta,\lambda)=-cg_{1}(\theta,\lambda)-g_{2}(\theta,\lambda)$
\end_inset

 and so:
\begin_inset Formula 
\[
\frac{\partial f_{3}}{\partial\theta}=-c\frac{\partial}{\partial\theta}g_{1}(\theta,\lambda)-\frac{\partial}{\partial\theta}g_{2}(\theta,\lambda)=-\frac{\lambda}{2}\frac{\partial f_{2}}{\partial\theta}(\theta)=-\lambda H^{T}(H\theta-y)
\]

\end_inset

and:
\begin_inset Formula 
\[
\frac{\partial f_{3}}{\partial\lambda}=-c\frac{\partial}{\partial\lambda}g_{1}(\theta,\lambda)-\frac{\partial}{\partial\lambda}g_{2}(\theta,\lambda)=-\frac{c}{\lambda}-\frac{1}{2}\stackrel[i=1]{n}{\sum}(h_{i}^{T}\theta-y_{i})^{2}=-\frac{c}{\lambda}-\frac{1}{2}\left\Vert H\theta-y\right\Vert ^{2}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
\begin_inset Formula $\hat{\theta}$
\end_inset

 which maximaizes 
\begin_inset Formula $f_{3}$
\end_inset

 holds 
\begin_inset Formula $\frac{\partial f_{3}}{\partial\theta}(\hat{\theta},\lambda)=0$
\end_inset

 (as 
\begin_inset Formula $f_{3}$
\end_inset

 is concave):
\end_layout

\begin_layout Paragraph
\begin_inset Formula 
\[
0=-\lambda H^{T}(H\hat{\theta}-y)\underset{0<\lambda}{\Longrightarrow}0=H^{T}(H\hat{\theta}-y)\Longrightarrow H\hat{\theta}=y\Longrightarrow\hat{\theta}=H^{-1}y
\]

\end_inset


\begin_inset Formula 
\begin{align*}
H^{T}y & =H^{T}H\hat{\theta}\\
\theta= & \left(H^{T}H\right)^{-1}H^{T}y
\end{align*}

\end_inset

 And we can see it doesn't depent on 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Same as before:
\end_layout

\begin_layout Paragraph
\begin_inset Formula 
\[
0=\frac{\partial f_{3}}{\partial\lambda}(\theta,\hat{\lambda})=-\frac{c}{\hat{\lambda}}-\frac{1}{2}\left\Vert H\theta-y\right\Vert ^{2}\Longrightarrow\frac{1}{2}\left\Vert H\theta-y\right\Vert ^{2}=-\frac{c}{\hat{\lambda}}\Longrightarrow\hat{\lambda}=-\frac{2c}{\left\Vert H\theta-y\right\Vert ^{2}}
\]

\end_inset

And here 
\begin_inset Formula $\hat{\lambda}$
\end_inset

 depends on 
\begin_inset Formula $\theta$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Maximize 
\begin_inset Formula $f_{3}$
\end_inset


\end_layout

\begin_layout Paragraph
problem ):
\end_layout

\begin_layout Section
Probability
\end_layout

\begin_layout Subsection
Suppose we have some way to predict whether it will rain tomorrow using
 some fancy machine.
 We know that the probability that it will predict rain when there actually
 won’t be any is 
\begin_inset Formula $p_{FP}$
\end_inset

 (the “FP” stands for false positive).
 Conversely, the probability it predicts dry conditions when there will
 be rain is 
\begin_inset Formula $p_{FN}$
\end_inset

 (the “FN” stands for false negative).
 We also somehow know that the probability that tomorrow will be rainy is
 
\begin_inset Formula $p_{r}$
\end_inset

.
 What is the probability that there will be rain if our machine said there
 won’t be?
\end_layout

\begin_layout Paragraph
We want P(
\begin_inset Quotes eld
\end_inset

it will rain
\begin_inset Quotes erd
\end_inset

 | 
\begin_inset Quotes eld
\end_inset

machine said it won’t rain
\begin_inset Quotes erd
\end_inset

).
 Denote A={
\begin_inset Quotes eld
\end_inset

it will rain
\begin_inset Quotes erd
\end_inset

}, B={
\begin_inset Quotes eld
\end_inset

machine said it won’t rain
\begin_inset Quotes erd
\end_inset

}.
 What is P(A|B).
 According to Bayes’ law: 
\begin_inset Formula $P(A|B)=\frac{P(A)P(B|A)}{P(B)}$
\end_inset

.
 P(B|A)=P(
\begin_inset Quotes eld
\end_inset

machine said it won’t rain
\begin_inset Quotes erd
\end_inset

 | 
\begin_inset Quotes eld
\end_inset

it will rain
\begin_inset Quotes erd
\end_inset

) = 
\begin_inset Formula $p_{FN}$
\end_inset

.
 Furthermore - P(A)=P(
\begin_inset Quotes eld
\end_inset

it will rain
\begin_inset Quotes erd
\end_inset

)=
\begin_inset Formula $p_{r}$
\end_inset

.
 All we need now is P(B)=P(
\begin_inset Quotes eld
\end_inset

machine said it won’t rain
\begin_inset Quotes erd
\end_inset

).
 By the law of total probability we get 
\begin_inset Formula $P(B)$
\end_inset

 = 
\begin_inset Formula $P(B|A)p_{r}+P(B|!A)(1-p_{r})=p_{FN}\cdot p_{r}+P(B|!A)(1-p_{r})$
\end_inset

.
 So we want - P(B|
\begin_inset Formula $!A$
\end_inset

) = P(
\begin_inset Quotes eld
\end_inset

machine said it won’t rain
\begin_inset Quotes erd
\end_inset

| NOT 
\begin_inset Quotes eld
\end_inset

it will rain
\begin_inset Quotes erd
\end_inset

) = P(
\begin_inset Quotes eld
\end_inset

machine said it won’t rain
\begin_inset Quotes erd
\end_inset

| 
\begin_inset Quotes eld
\end_inset

it will not rain
\begin_inset Quotes erd
\end_inset

) i.e.
 the qusestion is what's the probabilty to get a True Positive which is
 
\begin_inset Formula $1-p_{FP}.$
\end_inset

 Thus:
\begin_inset Formula 
\begin{align*}
P(B) & =p_{FN}\cdot p_{r}+(1-p_{FP})(1-p_{r})=p_{FN}\cdot p_{r}+(1-p_{r})-p_{FP}(1-p_{r})=\\
p_{FN}p_{r}+1-p_{r}-p_{FP}+p_{r}p_{FP}= & 1-p_{r}(1-p_{FN})+p_{FP}(1-p_{r})
\end{align*}

\end_inset

So:
\end_layout

\begin_layout Paragraph
\begin_inset Formula 
\[
P(A|B)=\frac{p_{r}\cdot p_{FN}}{1-p_{r}(1-p_{FN})+p_{FP}(1-p_{r})}
\]

\end_inset


\end_layout

\begin_layout Subsection
Uniform random variable on a segment in 
\begin_inset Formula $\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
We know 
\begin_inset Formula $1=\stackrel[-\infty]{\infty}{\int}PDF(x)dx$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
So, because the p(x) is non zero only in the interval 
\begin_inset Formula $[m-\frac{d}{2},m+\frac{d}{2}]$
\end_inset

:
\begin_inset Formula 
\[
1=\stackrel[-\infty]{m-\frac{d}{2}}{\int}0dx+\stackrel[m-\frac{d}{2}]{m+\frac{d}{2}}{\int}\frac{1}{c}dx+\stackrel[m+\frac{d}{2}]{\infty}{\int}0dx=\stackrel[m-\frac{d}{2}]{m+\frac{d}{2}}{\int}\frac{1}{c}dx=\frac{1}{c}\stackrel[m-\frac{d}{2}]{m+\frac{d}{2}}{\int}dx=\frac{1}{c}\cdot x|_{m-\frac{d}{2}}^{m+\frac{d}{2}}=\frac{1}{c}(m+\frac{d}{2}-(m-\frac{d}{2}))=\frac{d}{c}
\]

\end_inset

 Multiply by c and we get c=d.
\end_layout

\begin_layout Subsubsection
Mean and Variance
\end_layout

\begin_layout Paragraph
For the mean we use 
\begin_inset Formula $E[x]=\stackrel[-\infty]{\infty}{\int}xp(x)dx$
\end_inset

.
 As above:
\begin_inset Formula 
\begin{align*}
E[x] & =\stackrel[m-\frac{d}{2}]{m+\frac{d}{2}}{\int}\frac{x}{c}dx=\frac{1}{c}\stackrel[m-\frac{d}{2}]{m+\frac{d}{2}}{\int}xdx=\frac{1}{2c}\cdot x^{2}|_{m-\frac{d}{2}}^{m+\frac{d}{2}}=\frac{1}{2c}((m+\frac{d}{2})^{2}-(m-\frac{d}{2})^{2})=\\
= & \frac{1}{2c}(m^{2}+md+\frac{d^{2}}{4}-(m^{2}-md+\frac{d^{2}}{4}))=\frac{1}{2c}(md+md)=\frac{md}{c}\underset{c=d}{=}m=E[x]
\end{align*}

\end_inset

 As for the variance - 
\begin_inset Formula $var(x)=E[x^{2}]-E[x]^{2}$
\end_inset

.
 By the computation above - 
\begin_inset Formula $E[x]^{2}=m^{2}$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
According to 4.10 in the recitation 
\begin_inset Formula $E[x^{2}]=E[f(x)]=\int p(x)f(x)dx$
\end_inset

 for 
\begin_inset Formula $f(x)=x^{2}$
\end_inset

 .
 We compute:
\begin_inset Formula 
\begin{align*}
E[f(x)] & =\stackrel[-\infty]{m-\frac{d}{2}}{\int}0\cdot x^{2}dx+\stackrel[m-\frac{d}{2}]{m+\frac{d}{2}}{\int}\frac{1}{c}x^{2}dx+\stackrel[m+\frac{d}{2}]{\infty}{\int}0\cdot x^{2}dx=\frac{1}{c}\stackrel[m-\frac{d}{2}]{m+\frac{d}{2}}{\int}x^{2}dx=\\
\underset{c=d}{=} & \frac{1}{3d}((m+\frac{d}{2})^{3}-(m-\frac{d}{2})^{3})=\frac{d^{3}}{12d}+\frac{dm^{2}}{d}=\frac{d^{2}}{12}+m^{2}=E[x^{2}]
\end{align*}

\end_inset

Finally - 
\begin_inset Formula $var(x)=E[x^{2}]-E[x]^{2}=\frac{d^{3}}{12d}+m^{2}-m^{2}=\frac{d^{3}}{12d}=\frac{d^{2}}{12}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
\begin_inset Formula $y=x+\delta$
\end_inset


\end_layout

\begin_layout Paragraph
According to the 
\begin_inset Quotes eld
\end_inset

Change of variable
\begin_inset Quotes erd
\end_inset

 rule from the recitation (4.24) we know 
\begin_inset Formula $p_{y}(y)=p_{x}(f^{-1}(y))\cdot det(J_{y}(f^{-1}(y)))$
\end_inset

.
 As 
\begin_inset Formula $f^{-1}(y)=y-\delta$
\end_inset

 and we're talking about 1D real functions - 
\begin_inset Formula $det(J_{y}(f^{-1}(y)))=\frac{\partial f^{-1}}{\partial y}(y)=1$
\end_inset

 and so 
\begin_inset Formula 
\[
p_{y}(y)=p_{x}(f^{-1}(y))=\begin{cases}
\frac{1}{d} & m-\frac{d}{2}\le f^{-1}(y)\le m+\frac{d}{2}\\
0 & else
\end{cases}=\begin{cases}
\frac{1}{d} & m-\frac{d}{2}+\delta\le y\le m+\frac{d}{2}+\delta\\
0 & else
\end{cases}
\]

\end_inset

 Now note that if we take 
\begin_inset Formula $\hat{m}=m+\delta$
\end_inset

 and 
\begin_inset Formula 
\[
\hat{p}_{z}(z)=\begin{cases}
\frac{1}{d} & m-\frac{d}{2}\le z\le m+\frac{d}{2}\\
0 & else
\end{cases}
\]

\end_inset

We're back to the conditions of our original question, meaning the mean
 and variance of a uniform random variable in a real segment are invariant
 to shifts of the segment.
 I.e.
 
\begin_inset Formula $E(y)=m^{2}$
\end_inset

 and 
\begin_inset Formula $var(y)=\frac{d^{2}}{12}$
\end_inset

.
\end_layout

\begin_layout Subsection
Let 
\begin_inset Formula $x,y$
\end_inset

 be independent continuous random vectors 
\end_layout

\begin_layout Paragraph
\begin_inset Formula 
\begin{align*}
E[xy^{T}] & =E\left[\begin{array}{ccc}
x_{1}y_{1} & \ldots & x_{1}y_{m}\\
\vdots & \vdots & \vdots\\
x_{n}y_{1} & \ldots & x_{n}y_{m}
\end{array}\right]=\left[\begin{array}{ccc}
E[x_{1}y_{1}] & \ldots & E[x_{1}y_{m}]\\
\vdots & \vdots & \vdots\\
E[x_{n}y_{1}] & \ldots & E[x_{n}y_{m}]
\end{array}\right]=\left[\begin{array}{ccc}
[- & E[x_{1}y] & -]\\
 & \vdots\\{}
[- & E[x_{n}y] & -]
\end{array}\right]=_{\blacktriangle}\left[\begin{array}{ccc}
[- & x_{1}E[y] & -]\\
 & \vdots\\{}
[- & x_{n}E[y] & -]
\end{array}\right]=\\
= & x^{T}\left[\begin{array}{ccc}
[- & E[y] & -]\\
 & \vdots\\{}
[- & E[y] & -]
\end{array}\right]=x^{T}\left[\begin{array}{ccc}
E[y_{1}] & ... & E[y_{y}]\\
 & \vdots\\{}
[- & E[y] & -]
\end{array}\right]
\end{align*}

\end_inset

And 
\begin_inset Formula $\blacktriangle$
\end_inset

 is due to the linearity of E.
 So the i'th row is 
\begin_inset Formula $E[x_{i}y]=\int x_{i}yp(y)dy=x_{i}\int yp(y)dy$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Lemma: If x and y are independent continuous random vectors than for each
 i,j - 
\begin_inset Formula $x_{i},y_{j}$
\end_inset

 are independent.
\end_layout

\begin_layout Paragraph
Proof: 
\begin_inset Formula $p(x,y)=p(x)p(y)=p$
\end_inset


\end_layout

\begin_layout Subsection
\begin_inset Formula $cov\left[Hx+\eta\right]$
\end_inset


\end_layout

\begin_layout Paragraph
From the recitation (4.19) 
\begin_inset Formula $cov[y]=cov[yy^{T}]=E[yy^{T}]-E[y]E[y^{T}]$
\end_inset

 .
 Also 
\begin_inset Formula $\left[Hx+\eta\right]_{i}=[Hx]_{i}+\eta_{i}=H_{i}^{T}x_{j}+\eta_{i}=\left[\sum H_{ij}x_{j}\right]+\eta_{i}$
\end_inset

.
 So 
\begin_inset Formula 
\[
yy^{T}=\left[Hx+\eta\right]\left[Hx+\eta\right]^{T}=\left[\begin{array}{ccc}
y_{1}y_{1} & ... & y_{1}y_{q}\\
 & \vdots\\
y_{1}y_{q} & ... & y_{q}y_{q}
\end{array}\right]=
\]

\end_inset


\end_layout

\end_body
\end_document
