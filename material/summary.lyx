#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\begin_modules
eqs-within-sections
theorems-named
figs-within-sections
tabs-within-sections
subequations
theorems-starred
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Part
Lec
\end_layout

\begin_layout Paragraph
Bayes' law (Inverse Probability): 
\begin_inset Formula 
\[
P(A|B)=\frac{P(A,B)}{P(B)}=\frac{P(A)P(B|A)}{P(B)}
\]

\end_inset

In our terms: 
\begin_inset Formula 
\[
P(\theta|D)=\frac{P(\theta)P(D|\theta)}{P(D)}=\frac{P(\theta)P(D|\theta)}{\int P(\theta)P(D|\theta)d\theta}
\]

\end_inset


\end_layout

\begin_layout Definition
MSE Estimator: 
\begin_inset Formula 
\[
MSE(\hat{\theta}(D))=E_{D}\left[\left\Vert \theta-\hat{\theta}(D)\right\Vert ^{2}\right]
\]

\end_inset


\end_layout

\begin_layout Definition
BMSE Estimator: 
\begin_inset Formula 
\[
BMSE(\hat{\theta}(D))=E_{\theta,D}\left[\left\Vert \theta-\hat{\theta}(D)\right\Vert ^{2}\right]=\int_{\theta,D}P(\theta,D)\left\Vert \theta-\hat{\theta}(D)\right\Vert ^{2}d\theta dD
\]

\end_inset


\end_layout

\begin_layout Theorem*
Regarding the BMSE estimator, the optimal bayesian estimation of 
\begin_inset Formula $\theta$
\end_inset

 is: 
\begin_inset Formula 
\[
\hat{\theta}_{MMSE}=E[\theta|D]
\]

\end_inset


\end_layout

\begin_layout Paragraph
For a new likelihood function: 
\begin_inset Formula 
\[
L_{\epsilon}\left(\theta,\hat{\theta}\right)\begin{cases}
0 & \left\Vert \theta-\hat{\theta}\right\Vert <\epsilon\\
1 & else
\end{cases}
\]

\end_inset

And a new astimator - Max Aposeriori 
\begin_inset Formula $\left(\hat{\theta}_{MAP}\right)$
\end_inset

 the following are optimal estimators with regards to their likelihood function
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\hat{\theta}_{MLE}= & \underset{\theta}{agrmax}P(D|\theta)\\
\hat{\theta}_{MMSE}= & E[\theta|D]\\
\hat{\theta}_{MAP}= & \underset{\theta}{agrmax}P(\theta|D)
\end{align*}

\end_inset


\end_layout

\begin_layout Part
Rec
\end_layout

\begin_layout Definition
1D Gaussion: 
\begin_inset Formula $x\sim N(\mu,\sigma^{2})\equiv N(x|\mu,\sigma^{2})$
\end_inset


\begin_inset Formula 
\[
p(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left[-\frac{1}{2\sigma^{2}}(x-\mu)^{2}\right]
\]

\end_inset

d-Dims Gaussion: 
\begin_inset Formula $x\sim N(\mu,\Sigma)$
\end_inset


\begin_inset Formula 
\[
p(x)=\frac{1}{\sqrt{\left(2\pi\right)^{d}\left|\Sigma\right|}}\exp\left[-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu)\right]
\]

\end_inset

 Where's 
\begin_inset Formula $\Sigma$
\end_inset

 is symmetric.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
Mahalanobis distance, Denoted with 
\begin_inset Formula $\Delta$
\end_inset

 is: 
\begin_inset Formula 
\[
\Delta=D_{M}\left(x|\mu,\Sigma\right)^{2}=(x-\mu)^{T}\Sigma^{-1}(x-\mu)
\]

\end_inset


\end_layout

\begin_layout Lemma
For 
\begin_inset Formula $x\sim N(\mu,\Sigma)$
\end_inset

 we get 
\begin_inset Formula 
\begin{align*}
E[x]= & \mu\\
E[xx^{T}]= & \Sigma+\mu\mu^{T}\\
cov(x)= & \Sigma
\end{align*}

\end_inset


\end_layout

\begin_layout Fact*
As 
\begin_inset Formula $\Sigma$
\end_inset

 is symmetric, it's PD, so we can write 
\begin_inset Formula $\Sigma^{-1}=\sum\frac{1}{\lambda_{i}}u_{i}u_{i}^{T}$
\end_inset

 such that the 
\begin_inset Formula $\{\lambda_{i}\}'s$
\end_inset

 are the eignvalues of 
\begin_inset Formula $\Sigma$
\end_inset

 and 
\begin_inset Formula $\{u_{i}\}_{i}$
\end_inset

 is the orthonormal basis for which 
\begin_inset Formula $\Sigma$
\end_inset

 is a diagonal matix.
 Under those terms we can present the contour lines of the distribution
 as an ellipsoids:
\begin_inset Formula 
\[
\Delta=\sum_{i}\left(\frac{u_{i}^{T}(x-\mu)}{\sqrt{\lambda}_{i}}\right)^{2}
\]

\end_inset


\end_layout

\begin_layout Paragraph
Notice any distribution of the form: 
\begin_inset Formula $p(x)\propto\exp\left[x^{T}\Gamma x+b^{T}x+c\right]$
\end_inset

 is a Gaussion.
 I.e.
 any bilinear form in an exponent is a Gaussion.
\end_layout

\begin_layout Corollary
The Derivative Trick: 
\begin_inset Formula $\frac{\partial\Delta}{\partial x}=\Sigma^{-1}(x-\mu)$
\end_inset

 and 
\begin_inset Formula $\frac{\partial\Delta}{\partial x\partial x^{T}}=\Sigma^{-1}$
\end_inset

.
 So given such a distribution, if we can write down 
\begin_inset Formula 
\[
\frac{\partial}{\partial x}-\log(p(x))=\Sigma^{-1}(x-\mu)
\]

\end_inset

for some 
\begin_inset Formula $\Sigma$
\end_inset

 and 
\begin_inset Formula $\mu$
\end_inset

, we can describe the distribution.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Paragraph
——————————–
\end_layout

\begin_layout Paragraph
We know 
\begin_inset Formula $\theta\sim N\left(\mu,\Sigma\right)$
\end_inset

 and 
\begin_inset Formula $D_{i}|\theta\sim N(H_{i}\theta,\sigma^{2}I)$
\end_inset

 so using Bayes' law and Q3 we know:
\begin_inset Formula 
\[
p(\theta|D_{1},D_{2})=\frac{p(\theta,D_{1},D_{2})}{p(D_{1},D_{2})}\propto p(\theta,D_{1},D_{2})=p(\theta)p(D_{1}|\theta)p(D_{2}|\theta)
\]

\end_inset

So, we can write the PDF of 
\begin_inset Formula $p(\theta|D_{1},D_{2})$
\end_inset

 as the multiplication of three Guassions.
 Specifically, it's also a Guassion and in order to descibe it we need its
 mean and covariance.
 Using the derivative trick we only need to look at the sum in the exponent:
\begin_inset Formula 
\[
2\Delta=(x-\mu)^{T}\Sigma^{-1}(x-\mu)+\frac{1}{\sigma^{2}}\sum_{i=[1,2]}\left\Vert H_{i}\theta-x\right\Vert 
\]

\end_inset


\end_layout

\end_body
\end_document
